{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[-0.3056, -0.2502, -0.1151, -0.1344, -1.4462, -1.2061, -0.3810,\n           0.3697, -0.3140,  0.7101,  0.5875,  0.9239,  0.8547, -0.4835,\n          -0.5631,  0.4409,  0.0294,  1.3858, -3.1313, -1.5738],\n         [ 0.3428,  1.1288, -0.3470, -1.9055, -0.8913, -0.4335,  2.3119,\n          -1.4110, -0.4648,  0.2264, -1.7857,  0.9380,  1.2593,  0.5636,\n          -0.8744, -0.0256,  0.3173, -0.6592,  0.7471,  0.3569],\n         [ 0.6094,  0.7370,  1.2534, -0.1765, -0.0745, -0.3292,  1.6391,\n          -0.4543,  0.6439,  0.8137,  0.8034, -0.0803,  0.1001, -1.1750,\n           1.4378, -0.5102, -0.7792, -1.4679, -0.2817, -0.4222]],\n\n        [[ 0.0133, -1.1547, -1.4468, -0.4599, -0.6032, -1.6393, -1.7404,\n           0.4116,  0.7275,  0.5113, -0.4436,  0.7263,  0.3210, -2.7261,\n           2.0588, -0.9359, -0.6770, -1.1320, -1.4527, -2.7223],\n         [-2.2226,  1.4286, -0.7130, -0.9019, -0.9149, -1.9909,  1.3421,\n           2.0358,  0.4548,  1.0056,  0.1198, -0.4054,  0.1768, -0.4993,\n          -0.0534, -0.7641, -0.4009,  0.6733, -0.9958,  0.5632],\n         [ 0.9158, -0.9092,  0.3529, -0.0893, -0.1546, -0.5814,  0.7255,\n           0.1047, -0.2046,  0.6391,  1.3679, -2.0662, -0.8491,  1.2309,\n          -0.4426, -1.1687, -1.9137, -0.1762,  0.7562, -0.5246]]])"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2, 3, 20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RNN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters\n",
    "# input_size = 784 # 28x28\n",
    "num_classes = 10\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "initial_lr = 0.001\n",
    "\n",
    "input_size = 28\n",
    "sequence_length = 28\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "\n",
    "# MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root='./dataset',\n",
    "                                           train=True,\n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./dataset',\n",
    "                                          train=False,\n",
    "                                          transform=transforms.ToTensor(),\n",
    "                                          download=True)\n",
    "\n",
    "# Data loader  image,targets的数据形式\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        # 这一部分的书写主要对应在观察RNN的parameters，需要input_size, hidden_size, num_layers和batch_first\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        # 这里的batch_first=True 影响的是后来输入input的x 而不是这里的RNN model\n",
    "        self.linear = nn.Linear(in_features=hidden_size, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x作为input在batch_first=True的时候应该输入的形状为N，L，Hin\n",
    "        # 同时同时作为输入的还有h_0, (1*num_layers, N, Hout)\n",
    "        # 这一部分的书写主要对应于inputs，x要满足input形状条件，同时提供符合形状条件的h0\n",
    "        h_0 = torch.zeros(size=(self.num_layers, x.shape[0], self.hidden_size)).to(device)\n",
    "\n",
    "        # 这一部分的书写主要对应于output部分，观察output输出几部分，分别是什么，对于模型，我们需要的是哪一部分，找到筛选对应的部分\n",
    "        output, _ = self.rnn(x, h_0)   # 这里只选择要output，不要每一次计算生成的新的hidden_size\n",
    "\n",
    "        # output的形状是下图的（N，L，D*Hout），最后一个纬度的Hout就是hidden_size\n",
    "        output_last = output[:, -1, :]\n",
    "        # output形状是\n",
    "        final = self.linear(output_last)\n",
    "        return final"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 模型编写部分"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](img_6.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inputs书写部分"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](img_4.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Output选择筛选部分"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](img_5.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN: Epoch [1/2], Step [100/600], Loss: 1.0202053785324097\n",
      "RNN: Epoch [1/2], Step [200/600], Loss: 0.9119145274162292\n",
      "RNN: Epoch [1/2], Step [300/600], Loss: 0.769856870174408\n",
      "RNN: Epoch [1/2], Step [400/600], Loss: 0.43682318925857544\n",
      "RNN: Epoch [1/2], Step [500/600], Loss: 0.3267645239830017\n",
      "RNN: Epoch [1/2], Step [600/600], Loss: 0.3402518332004547\n",
      "RNN: Epoch [2/2], Step [100/600], Loss: 0.3188333809375763\n",
      "RNN: Epoch [2/2], Step [200/600], Loss: 0.2547306418418884\n",
      "RNN: Epoch [2/2], Step [300/600], Loss: 0.22514106333255768\n",
      "RNN: Epoch [2/2], Step [400/600], Loss: 0.2613934278488159\n",
      "RNN: Epoch [2/2], Step [500/600], Loss: 0.24806368350982666\n",
      "RNN: Epoch [2/2], Step [600/600], Loss: 0.19717146456241608\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model = RNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers).to(device)\n",
    "\n",
    "# SummaryWriter\n",
    "writer = SummaryWriter(log_dir='RNN_Logs')\n",
    "\n",
    "# Optimizer and Loss func\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=initial_lr)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "n_total_steps = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Train\n",
    "    model.train()\n",
    "    for i, (imgs, labels) in enumerate(train_loader):\n",
    "        writer.add_images(tag='Orginal', img_tensor=imgs, global_step=i)\n",
    "\n",
    "        # Reshape\n",
    "        # print(imgs.shape) # Size([100, 1, 28, 28])\n",
    "        # 根据RNN模型要求，我们需要的是（N，L，H），不需要Channel\n",
    "        imgs = imgs.reshape(-1, sequence_length, input_size).to(device)\n",
    "\n",
    "        # imgs = imgs.reshape(-1, 2, 28, 28).to(device)\n",
    "        # writer.add_images(tag='After', img_tensor=imgs, global_step=i)\n",
    "        # dataformats='NCHW'，这里会默认有Channel，同时对于图片来说，单通道的图片无法转化成RGB---3通道图片，也无法变成2个通道的照片，无法显示\n",
    "        # 因而上面writer.add_images行是无法正常运行的 会报错\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(imgs)\n",
    "\n",
    "        # Loss&Optimizer\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        writer.add_scalar(tag='RNN_Train_Loss', scalar_value=loss, global_step=i+1)\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'RNN: Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the RNN on the 10000 test images: 94.9800 %\n",
      "RNN TOTAL LOSS: 18.07237434387207\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "RNN_Total_Loss = 0\n",
    "test_samples = 0\n",
    "test_correct = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs = imgs.reshape(-1, sequence_length, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "        test_output = model(imgs)\n",
    "        loss = loss_fn(test_output, labels)\n",
    "        # max\n",
    "        _, result_indices = torch.max(test_output, dim=1)\n",
    "        RNN_Total_Loss += loss\n",
    "        test_samples += len(labels)\n",
    "        test_correct += (result_indices == labels).sum().item()\n",
    "    print(f'Accuracy of the RNN on the 10000 test images: {test_correct*100/test_samples:.4f} %')\n",
    "    print(f'RNN TOTAL LOSS: {RNN_Total_Loss}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LSTM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters\n",
    "# input_size = 784 # 28x28\n",
    "num_classes = 10\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "initial_lr = 0.001\n",
    "\n",
    "input_size = 28\n",
    "sequence_length = 28\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "\n",
    "# MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root='./dataset',\n",
    "                                           train=True,\n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./dataset',\n",
    "                                          train=False,\n",
    "                                          transform=transforms.ToTensor(),\n",
    "                                          download=True)\n",
    "\n",
    "# Data loader  image,targets的数据形式\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        # 这一部分的书写主要对应在观察RNN的parameters，需要input_size, hidden_size, num_layers和batch_first\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        # 这里的batch_first=True 影响的是后来输入input的x 而不是这里的RNN model\n",
    "        self.linear = nn.Linear(in_features=hidden_size, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x作为input在batch_first=True的时候应该输入的形状为N，L，Hin\n",
    "        # 同时同时作为输入的还有h_0, (1*num_layers, N, Hout)\n",
    "        # 这一部分的书写主要对应于inputs，x要满足input形状条件，同时提供符合形状条件的h0\n",
    "        h_0 = torch.zeros(size=(self.num_layers, x.shape[0], self.hidden_size)).to(device)\n",
    "        c_0 = torch.zeros(size=(self.num_layers, x.shape[0], self.hidden_size)).to(device)\n",
    "\n",
    "        # 这一部分的书写主要对应于output部分，观察output输出几部分，分别是什么，对于模型，我们需要的是哪一部分，找到筛选对应的部分\n",
    "        output, _= self.lstm(x, (h_0, c_0))   # 这里只选择要output，不要每一次计算生成的新的hidden_size\n",
    "        # 注意LSTM的是要求(h_0, c_0)要合在一起；同时output也是output, (h_n, c_n)的形式\n",
    "\n",
    "        # output的形状是下图的（N，L，D*Hout），最后一个纬度的Hout就是hidden_size\n",
    "        # Decode the hidden state of the last time step\n",
    "        output_last = output[:, -1, :]\n",
    "        # output形状是\n",
    "        final = self.linear(output_last)\n",
    "        return final"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN: Epoch [1/2], Step [100/600], Loss: 0.5816653370857239\n",
      "RNN: Epoch [1/2], Step [200/600], Loss: 0.39331120252609253\n",
      "RNN: Epoch [1/2], Step [300/600], Loss: 0.3043815493583679\n",
      "RNN: Epoch [1/2], Step [400/600], Loss: 0.10253220796585083\n",
      "RNN: Epoch [1/2], Step [500/600], Loss: 0.06371147185564041\n",
      "RNN: Epoch [1/2], Step [600/600], Loss: 0.16674530506134033\n",
      "RNN: Epoch [2/2], Step [100/600], Loss: 0.1519927829504013\n",
      "RNN: Epoch [2/2], Step [200/600], Loss: 0.12093736976385117\n",
      "RNN: Epoch [2/2], Step [300/600], Loss: 0.08417823910713196\n",
      "RNN: Epoch [2/2], Step [400/600], Loss: 0.09751875698566437\n",
      "RNN: Epoch [2/2], Step [500/600], Loss: 0.08690796792507172\n",
      "RNN: Epoch [2/2], Step [600/600], Loss: 0.20972710847854614\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model = LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers).to(device)\n",
    "\n",
    "# SummaryWriter\n",
    "writer = SummaryWriter(log_dir='LSTM_Logs')\n",
    "\n",
    "# Optimizer and Loss func\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=initial_lr)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "n_total_steps = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Train\n",
    "    model.train()\n",
    "    for i, (imgs, labels) in enumerate(train_loader):\n",
    "        writer.add_images(tag='Orginal', img_tensor=imgs, global_step=i)\n",
    "\n",
    "        # Reshape\n",
    "        # print(imgs.shape) # Size([100, 1, 28, 28])\n",
    "        # 根据RNN模型要求，我们需要的是（N，L，H），不需要Channel\n",
    "        imgs = imgs.reshape(-1, sequence_length, input_size).to(device)\n",
    "\n",
    "        # imgs = imgs.reshape(-1, 2, 28, 28).to(device)\n",
    "        # writer.add_images(tag='After', img_tensor=imgs, global_step=i)\n",
    "        # dataformats='NCHW'，这里会默认有Channel，同时对于图片来说，单通道的图片无法转化成RGB---3通道图片，也无法变成2个通道的照片，无法显示\n",
    "        # 因而上面writer.add_images行是无法正常运行的 会报错\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(imgs)\n",
    "\n",
    "        # Loss&Optimizer\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        writer.add_scalar(tag='RNN_Train_Loss', scalar_value=loss, global_step=i+1)\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'RNN: Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the LSTM on the 10000 test images: 97.3400 %\n",
      "RNN TOTAL LOSS: 8.772577285766602\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "LSTM_Total_Loss = 0\n",
    "test_samples = 0\n",
    "test_correct = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs = imgs.reshape(-1, sequence_length, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "        test_output = model(imgs)\n",
    "        loss = loss_fn(test_output, labels)\n",
    "        # max\n",
    "        _, result_indices = torch.max(test_output, dim=1)\n",
    "        LSTM_Total_Loss += loss\n",
    "        test_samples += len(labels)\n",
    "        test_correct += (result_indices == labels).sum().item()\n",
    "    print(f'Accuracy of the LSTM on the 10000 test images: {test_correct*100/test_samples:.4f} %')\n",
    "    print(f'RNN TOTAL LOSS: {LSTM_Total_Loss}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[2.5516, 0.0907]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1 = torch.randn(2).unsqueeze(0)\n",
    "print(input1.shape)\n",
    "input1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([0.9617, 0.9042])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input2 = torch.randn(2)\n",
    "print(input2.shape)\n",
    "input2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}